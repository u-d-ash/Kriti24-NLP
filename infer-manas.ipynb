{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7500256,"sourceType":"datasetVersion","datasetId":4367485}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim\n\nfrom transformers import BertTokenizer, BertModel\nfrom tqdm.notebook import tqdm\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NAMELIST = ['math.AT', 'stat.AP', 'cs.AR', 'math.QA', 'q-bio.MN', 'eess.AS','eess.IV', 'stat.ME', 'econ.GN',\n            'eess.SP', 'q-fin.RM', 'cs.LG', 'cs.CR', 'q-bio.BM', 'q-fin.GN', 'q-fin.MF', 'q-fin.PR', 'math.CV',\n            'cs.LO', 'econ.TH', 'math.CO', 'cs.AI', 'math.AC', 'q-bio.CB','q-fin.CP', 'cs.CL', 'cs.DC', 'math.LO', \n            'math.NT', 'cs.SD', 'q-fin.TR','cs.CV', 'stat.ML', 'q-fin.EC', 'econ.EM', 'cs.CE', 'stat.CO','math.PR', \n            'q-bio.NC', 'math.AP', 'cs.OS', 'cs.NI', 'cs.IT', 'cs.PL', 'cs.GT', 'cs.DM', 'math.IT', 'cs.SE', 'cs.RO', \n            'stat.TH', 'cs.DB','math.ST', 'q-bio.GN', 'q-fin.PM', 'q-bio.TO', 'math.GR', 'cs.IR']\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nLEARNING_RATE = 1e-5\nEPOCHS = 6\nTHRESHOLD = 0.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/kriti-dataset/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.sample(frac = 1, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = data[:48650]\nval_data = data[48650:] # 95-5 Split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_list_from_string(text): #parses list-string to list of strings\n\n    text = text[1:-1]\n    text = text.replace(\" \", \"\")\n    text = text.replace(\"'\", \"\")\n    list = text.split(',')\n\n    return list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_one_hot_vec(text):\n\n    wlist = get_list_from_string(text)\n\n    vec = []\n\n    for name in NAMELIST:\n\n        vec.append(1 if name in wlist else 0)\n    \n    return vec","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pylatexenc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pylatexenc.latex2text import LatexNodes2Text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef remove_space(text):\n    text = text.strip()\n    text = text.split()\n    return \" \".join(text)\n\ndef lowerall(text):\n    \n    text = text.split()\n    lwords = [word.lower() for word in text]\n    return \" \".join(lwords)\n\ndef remove_links(input_string):\n\n    pattern1 = r'\\\\href\\{.*?\\}\\{.*?\\}'\n    pattern2 = r'\\\\href\\{.*?\\}'\n    pattern3 = r'\\\\url\\{.*?\\}'\n\n    cleaned_string = re.sub(pattern1, '', input_string)\n    cleaned_string = re.sub(pattern2, '', cleaned_string)\n    cleaned_string = re.sub(pattern3, '', cleaned_string)\n    \n    return cleaned_string\n\ndef clean_text(text):\n    text = remove_space(text)\n    text = remove_links(text)\n    \n    text = LatexNodes2Text().latex_to_text(text)\n    \n    text = re.sub(r'[^a-zA-Z0-9\\s.,;:!?(){}\\[\\]<>+-/*=%$&@#~â‰¥\\\\_~`]', '', text)\n    \n    text = lowerall(text)\n    \n    return text\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TheDataset(Dataset):\n    \n    def __init__(self, df, test):\n        \n        self.IDs = df['Id'].values\n        Abstracts = df['Abstract'].values\n        Titles = df['Title'].values\n        \n        self.test = test\n        \n        self.Texts = []\n        \n        for i in range(len(self.IDs)):\n            \n            self.Texts.append(clean_text(Titles[i] + ' ' + Abstracts[i]))\n            \n\n        if not self.test:\n            \n            Cats = df['Categories'].values\n            self.Vectors = [get_one_hot_vec(cat) for cat in Cats]\n            \n\n    def __len__(self):\n        return len(self.IDs)\n    \n    def __getitem__(self, idx):\n        the_text = self.Texts[idx]\n        \n        inputs = bert_tokenizer.encode_plus(\n            the_text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length= 510,\n            padding='max_length',\n            return_token_type_ids=True\n        )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        if self.test:\n            return {\n                'textID' : self.IDs[idx],\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            }\n        else:\n            return {\n                'textID' : self.IDs[idx],\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n                'targets': torch.Tensor(self.Vectors[idx])\n            }\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NeuralNet(nn.Module):\n    \n    def __init__(self):\n        super(NeuralNet, self).__init__()\n        self.bert = BertModel.from_pretrained('allenai/scibert_scivocab_uncased')\n        self.fc1 = nn.Linear(768, 1024)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(1024, 57)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, features = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n        out1 = self.fc1(features)\n        out2 = self.relu(out1)\n        out = self.fc2(out2)\n        \n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = NeuralNet()\nmodel.to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\noptimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE, weight_decay = 1e-6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TheDataset(train_data, False)\nval_dataset = TheDataset(val_data, False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size = 8, num_workers = 4)\nval_loader = DataLoader(val_dataset, batch_size = 8, num_workers = 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer):\n    \n    losses = []\n    \n    model.train()\n\n    progress = tqdm(train_loader, total=len(train_loader))\n\n    for _, data in enumerate(progress):\n        \n        ids = data['ids'].to(DEVICE, dtype = torch.long)\n        mask = data['mask'].to(DEVICE, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n        \n        targets = data['targets'].to(DEVICE, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n\n        loss = loss_fn(outputs, targets)\n        losses.append(loss.item())\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()              \n\n\n    return np.mean(losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation(val_loader, model):\n    \n    model.eval()\n    \n    fin_targets=[]\n    fin_outputs=[]\n    \n    progress = tqdm(val_loader, total=len(val_loader))\n    \n    with torch.no_grad():\n        \n        for _, data in enumerate(progress):\n            \n            ids = data['ids'].to(DEVICE, dtype = torch.long)\n            mask = data['mask'].to(DEVICE, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n            \n            targets = data['targets'].to(DEVICE, dtype = torch.float)\n            \n            outputs = model(ids, mask, token_type_ids)\n            \n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            \n            outlist = torch.sigmoid(outputs).cpu().detach().numpy().tolist()\n        \n            one_hot_out = []\n            \n            for outl in outlist:\n                \n                yo = []\n                \n                for term in outl:\n                    \n                    if(term >= THRESHOLD):\n                        \n                        yo.append(1)\n                    \n                    else:\n                        \n                        yo.append(0)\n                \n                one_hot_out.append(yo)\n                \n            \n            fin_outputs.extend(one_hot_out)\n            \n    return fin_outputs, fin_targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/working/checkpoint.pth')['state_dict'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = []\n\nbest_dict = None\nbest_loss = np.inf\n\nfor ep in range(EPOCHS):\n\n    print('='*5 + f\" Epoch {ep+1} \" + '='*5)\n\n    tr_loss = train_fn(train_loader, model, loss_fn, optimizer)\n\n    if tr_loss < best_loss:\n        best_loss = tr_loss\n        best_dict = model.state_dict()\n        \n        checkpoint = {'model': model, 'state_dict': model.state_dict()}\n        torch.save(checkpoint, 'checkpoint.pth')\n\n    train_losses.append(tr_loss)\n\n    print(f\"Epoch {ep + 1} - Train Loss {tr_loss:.4f}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs, targets = validation(val_loader, model)\n\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n\nprint(f\"F1 Score (Macro) = {f1_score_macro}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds(test_loader, model):\n    \n    model.eval()\n    \n    fin_targets=[]\n    fin_outputs=[]\n    \n    progress = tqdm(test_loader, total=len(test_loader))\n    \n    with torch.no_grad():\n        \n        pred_dict = {}\n        \n        for _, data in enumerate(progress):\n            \n            textid = data['textID']\n            \n            ids = data['ids'].to(DEVICE, dtype = torch.long)\n            mask = data['mask'].to(DEVICE, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(DEVICE, dtype = torch.long)\n            \n            outputs = model(ids, mask, token_type_ids)\n    \n            outlist = torch.sigmoid(outputs).cpu().detach().numpy().tolist()\n        \n            one_hot_out = []\n            \n            for outl in outlist:\n                \n                yo = []\n                \n                for term in outl:\n                    \n                    if(term >= THRESHOLD):\n                        \n                        yo.append(1)\n                    \n                    else:\n                        \n                        yo.append(0)\n                \n                one_hot_out.append(yo)\n                \n            pred_dict[textid] = one_hot_out\n    \n            \n    return pred_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdf = pd.read_csv(\"/kaggle/input/kriti-dataset/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TheDataset(testdf, test = True)\ntest_loader  = DataLoader(test_dataset, batch_size = 8, num_workers = 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_dict = get_preds(test_loader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.DataFrame(list(pred_dict.items()), columns=['Id', 'OneHotVec'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred_dict = {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1372):\n    \n    for _, id in enumerate(pred_df['Id'][i]):\n        \n        id = id.numpy()\n        id = id.item()\n        \n        final_pred_dict[id] = pred_df['OneHotVec'][i][_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred_df = pd.DataFrame(list(final_pred_dict.items()), columns=['Id', 'OneHotVec'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, name in enumerate(NAMELIST):\n    \n    final_pred_df[name] = final_pred_df['OneHotVec'].apply(lambda x : x[i])\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred_df = final_pred_df.drop(['OneHotVec'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_pred_df.to_csv('manas.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}